{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2053f5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\users\\barba\\anaconda3\\lib\\site-packages (4.2.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\barba\\anaconda3\\lib\\site-packages (from optuna) (1.14.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\barba\\anaconda3\\lib\\site-packages (from optuna) (4.59.0)\n",
      "Requirement already satisfied: colorlog in c:\\users\\barba\\anaconda3\\lib\\site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\barba\\anaconda3\\lib\\site-packages (from optuna) (20.9)\n",
      "Requirement already satisfied: numpy in c:\\users\\barba\\anaconda3\\lib\\site-packages (from optuna) (1.20.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\barba\\anaconda3\\lib\\site-packages (from optuna) (5.4.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\barba\\anaconda3\\lib\\site-packages (from optuna) (1.4.7)\n",
      "Requirement already satisfied: Mako in c:\\users\\barba\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.9)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\barba\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (6.4.5)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\barba\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\barba\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (3.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\barba\\anaconda3\\lib\\site-packages (from packaging>=20.0->optuna) (2.4.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\barba\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (1.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\barba\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\barba\\anaconda3\\lib\\site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\barba\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "afbdf369",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.WARNING) #Eliminar prints ruidosos durante el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b2a7aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_recall_curve\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "\n",
    "#Cargar dataset\n",
    "file_path = \"dataset_Caso_1.csv\"\n",
    "df = pd.read_csv(file_path, delimiter=\",\")\n",
    "\n",
    "#Convertir columnas x1 y x2 a números asegurando que queden valores numéricos\n",
    "df[\"x1\"] = pd.to_numeric(df[\"x1\"], errors=\"coerce\")\n",
    "df[\"x2\"] = pd.to_numeric(df[\"x2\"], errors=\"coerce\")\n",
    "\n",
    "#Verificar si hay valores nulos tras la conversión y eliminarlos\n",
    "df.dropna(subset=[\"x1\",\"x2\"], inplace=True)\n",
    "\n",
    "#Convertir variables categóricas (x3 y x4) a numéricas usando LabelEncoder\n",
    "label_encoder_x3 = LabelEncoder()\n",
    "label_encoder_x4 = LabelEncoder()\n",
    "\n",
    "df['x3'] = label_encoder_x3.fit_transform(df['x3'])\n",
    "df['x4'] = label_encoder_x4.fit_transform(df['x4'])\n",
    "\n",
    "#Eliminar filas con valores NaN\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "#Separar las características(X) y la variable objetivo(y)\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target'].astype(int)  #Asegurar que target sea numérico\n",
    "\n",
    "#Calcular scale_pos_weight (para datos desbalanceados) #Hay considerablemente mayor cantidad de 0 que de 1\n",
    "num_neg = (y == 0).sum() #Contar clase 0\n",
    "num_pos = (y == 1).sum() #Contar clase 1\n",
    "scale_pos_weight = num_neg / num_pos\n",
    "\n",
    "#Dividir el dataset en 85% entrenamiento y 15% prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "    X, y, test_size=0.15, random_state=42, stratify=y #Usar stratify para que ambas clases tengan la misma proporción\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6505ecde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43aea575c200460bbdf715410ea2a6ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros encontrados: {'max_depth': 6, 'learning_rate': 0.00102084373660682, 'subsample': 0.5140277784709432, 'colsample_bytree': 0.953923815878277, 'lambda': 0.7769438351764247, 'alpha': 0.010118784188155818, 'n_estimators': 191, 'min_child_weight': 4, 'gamma': 3.9474720039996924}\n",
      "\n",
      "AUC Train: 0.9384\n",
      "AUC Test: 0.6633\n",
      "F1-Score: 0.3333\n"
     ]
    }
   ],
   "source": [
    "#Función objetivo para Optuna (Configuración hiperparámetros)\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'eval_metric': 'auc', \n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 9),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.3, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 0.6),  \n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'lambda': trial.suggest_float('lambda', 1e-3, 10, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-3, 10, log=True),\n",
    "        'scale_pos_weight': scale_pos_weight,\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 400),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 6), \n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),  #Evita overfitting\n",
    "        'random_state': 42 }\n",
    "\n",
    "    #Definir el modelo base de XGBoost\n",
    "    model = xgb.XGBClassifier(**params,)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_test_pred)    \n",
    "    return f1\n",
    "\n",
    "#Maximizar F1 con optuna\n",
    "study = optuna.create_study(direction=\"maximize\") \n",
    "study.optimize(objective, n_trials=100, show_progress_bar=True) #Barra de progreso hasta encontrar el mejor valor para F1\n",
    "\n",
    "#Obtener mejores hiperparámetros\n",
    "best_params = study.best_params\n",
    "print(\"Mejores hiperparámetros encontrados:\",best_params)\n",
    "\n",
    "#Entrenar el modelo con los mejores parámetros encontrados\n",
    "mejor_modelo = xgb.XGBClassifier(**best_params, eval_metric='auc', random_state=42, scale_pos_weight=scale_pos_weight)\n",
    "mejor_modelo.fit(X_train, y_train)\n",
    "\n",
    "#Predicciones en Train y Test\n",
    "y_train_pred = mejor_modelo.predict(X_train)\n",
    "y_test_pred = mejor_modelo.predict(X_test)\n",
    "\n",
    "#Calcular las probabilidades de la clase 1\n",
    "y_test_pred_proba = mejor_modelo.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#Calcular métricas\n",
    "auc_train = roc_auc_score(y_train, y_train_pred)\n",
    "auc_test = roc_auc_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "#Mostrar resultados\n",
    "print(f'\\nAUC Train: {auc_train:.4f}')\n",
    "print(f'AUC Test: {auc_test:.4f}')\n",
    "print(f'F1-Score: {f1:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
